{"cells":[{"cell_type":"code","execution_count":null,"id":"e2053c17-0b8e-4997-a013-14b1f4f316b0","metadata":{"id":"e2053c17-0b8e-4997-a013-14b1f4f316b0"},"outputs":[],"source":["import cv2\n","from djitellopy import Tello\n","import numpy as np\n","import time\n","import face_recognition"]},{"cell_type":"code","execution_count":null,"id":"c289ed3c-fa5b-4262-a060-e36f38a064ec","metadata":{"tags":[],"id":"c289ed3c-fa5b-4262-a060-e36f38a064ec"},"outputs":[],"source":["width, height = 360, 240\n","Forward_Backward_Range = [3000, 5000]\n","pid = [0.4,0.4,0]\n","pError = 0\n","drone = Tello()\n","drone.connect()\n","\n","print(drone.get_battery())\n","battery = (drone.get_battery())  # We want to learn battery from drone\n","if battery > 50:\n","    drone.streamon()  # Turn on video streaming\n","    drone.takeoff()\n","    drone.move_up(30)\n","else:\n","    print(\"please charge it\")\n","person_image = face_recognition.load_image_file(\"berkin99.jpg\")\n","person_face_encoding = face_recognition.face_encodings(person_image)[0]\n","\n","# Load a second sample picture and learn how to recognize it.\n","person2_image = face_recognition.load_image_file(\"biden.jpg\")\n","person2_face_encoding = face_recognition.face_encodings(person2_image)[0]\n","\n","# Create arrays of known face encodings and their names\n","known_face_encodings = [\n","    person_face_encoding,\n","    person2_face_encoding\n","]\n","known_face_names = [\n","    \"Berkin\",\n","    \"Joe Biden\"\n","]\n","\n","def trackFace(faceInfo,w,pid,pError):\n","    area = faceInfo[1]\n","    x, y = faceInfo[0]\n","    fb = 0\n","    error_x = x - w // 2  # w= width; finding center of face\n","    speed_x = pid[0] * error_x + pid[1] * (error_x - pError)   # determining the yaw\n","    speed_x = int(np.clip(speed_x, -100, 100))\n","\n","\n","    if area > Forward_Backward_Range[0] and area < Forward_Backward_Range[1]:\n","        fb = 0  \n","\n","    elif area > Forward_Backward_Range[1]:\n","        fb = -25\n","       \n","\n","    elif area < Forward_Backward_Range[0] and area != 0:  # If the drone is too far get closer\n","        fb = 25\n","     \n","\n","    elif area == 0:\n","        drone.rotate_clockwise(20)\n","        time.sleep(0.8)\n","\n","\n","\n","    if x == 0:\n","        speed_x = 0\n","        error_x = 0\n","    drone.send_rc_control(0, fb, 0, speed_x)\n","    print(speed_x, fb)\n","    return error_x\n","\n","\n","while True:\n","\n","    frame = drone.get_frame_read().frame\n","    img,info = cv2.resize(frame, (width, height))\n","\n","    rgb_frame = frame[:, :, ::-1]\n","\n","    # Find all the faces and face enqcodings in the frame of video\n","    face_locations = face_recognition.face_locations(rgb_frame)\n","    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n","\n","    # Loop through each face in this frame of video\n","    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n","        # See if the face is a match for the known face(s)\n","        matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n","\n","        name = \"Unknown\"\n","\n","        # If a match was found in known_face_encodings, just use the first one.\n","        # if True in matches:\n","        #     first_match_index = matches.index(True)\n","        #     name = known_face_names[first_match_index]\n","\n","        # Or instead, use the known face with the smallest distance to the new face\n","        face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n","        best_match_index = np.argmin(face_distances)\n","        if matches[best_match_index]:\n","            name = known_face_names[best_match_index]\n","\n","        # Draw a box around the face\n","        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n","\n","        # Draw a label with a name below the face\n","        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n","        font = cv2.FONT_HERSHEY_DUPLEX\n","        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n","\n","    pError = trackFace(info, width, pid, pError)\n","    cv2.imshow('Video', frame)\n","\n","    # Hit 'q' on the keyboard to quit!\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[{"file_id":"1yYqJLWf59db8H6OYC0Swid7rThviLRCx","timestamp":1686261530821}]}},"nbformat":4,"nbformat_minor":5}